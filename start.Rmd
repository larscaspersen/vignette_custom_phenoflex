---
title: "Working with PhenoFlex - Lars Edition"
output: distill::distill_article
bibliography: vignette_phenoflex.bib
csl: elsevier-harvard-modifed.csl
---

PhenoFlex is a phenology model [@luedeling_phenoflex_2021], accessible via the `chillR` package [@luedeling_chillr_2023]. During my PhD I mainly worked with PhenoFlex and worked out custimized functions. These functions made it easier for me to work with PhenoFlex, for example to integrate different calibration methods, calibration algortihms or to fit several phenological stages in one go. 

The standard PhenoFlex routines, from running the model, calibrating it, cross-validation and plotting the outputs of the chill and heat accumulation submodels is already nicely documented by @urbach_phenoflex_2021, see <https://cran.r-project.org/web/packages/chillR/vignettes/PhenoFlex.html>. These routines were the blueprint for the first phenology studies using PhenoFlex [@luedeling_phenoflex_2021; @fernandez_unusually_2022]. 

In these studies, many iterations of model calibration were carried out. That means you run the calibration fitting function `chillR::PhenologyFitter()`, wait and check if the estimated model parameters provide better predictions, if yes, then you start another round of calibration, using the estimated parameters as a new starting point. If they did not improve the predictions, you may want to change the search space, either make them wider or narrower to help the optimization algorithm to find new sets of parameters. 15 to 30 rounds of iterations were used to find the final set of parameters. This workflow resulted in fairly good parameters, the validation RMSE was below 4 days in these studies, however, it is a lot of work and takes quite a while. And most importantly, it is difficult to scale up the process, because it involves a lot of manual checking, adjusting search ranges, checking temperature response plots. 

One of my first tasks as a PhD was to apply PhenoFlex to an extensive phenology dataset assembled in the Adapting Mediterranean Orchards (AdaMedOr) project [@luedeling_long-term_2024]. The dataset comprised 270 cultivars of seven temperate fruit tree species (almond, pistachio, apple, pear, plum, sweet cherry, apricot). More than 100 cultivars had 20 or more observations [@caspersen_contrasting_2025], which is deemed to be the critical number of observations for model calibration [@urbach_phenoflex_2021]. For most of the cultivars we had 20 observations, so after a 75% calibration - 25% validation split only 5 observations are in the validation data set. Validating the model only on 5 observations seems quite a stretch, so we wanted to cross-validate the calibrated the model, so we had to even do more calibration steps.

## Intermediate chill submodel parameters

Together with Jose Egea, member of the AdaMedOr project consortium and experienced in global optimization problems, we hypothesized that part of the calibration problem are the ranges of the model parameters. In particular the parameters controlling the chill submodel. The Dynamic Model [@fishman_temperature-dependence_1987; @fishman_temperature_1987] consists of two ordinary differential equation (ODE) modeling the build-up and degradation of some (hypothetical) precursor of a dormancy breaking factor (PDBF). After a critical amount of PDBF is accumulated, a certain share gets converted to a non-degradable dormancy breaking factor (DBF). For the ODEs controlling build-up and degradation of PDBF four parameters are needed: $E_0$: activation energy for forming PDBF, $A_0$: amplitude of the formation process, $E_1$: activation energy for degrading PDBF and $A_1$: amplitude of the degradation process. All of these parameters are not really tangible for most people, so setting boundaries is difficult. It is even more difficult, because the default value of $A_1$ for example is on a ridiculous scale, 5.939917e13, that is a number wit 13 zeros before the digit! Good luck finding an appropriate search space that does not limit the algorithm too much but still is manageable. By the way, the default search space in @urbach_phenoflex_2021 might be too narrow, as in the original paper describing the Dynamic Model parameter they ranged from 0.1797e15 to 0.1875e17, while there the search space is "only" between 5.e13 to 6.e13. Also, they had initially ridiculous ranges in the other estimated model parameters, for instance $A_0$ ranged from 0.1386e4 to 0.1405e15. So in summary, finding appropriate ranges for these parameters is a difficult task, and even if you find them, it is a difficult search space for the optimization algorithm to navigate. Based on my limited experience, the optimizer is often "stuck" for these parameters and does not offer different sets of parameters for $E_0$, $E_1$, $A_0$ and $A_1$.

@egea_reducing_2021 point out, that the $E_0$ to $A_1$ parameters of the Dynamic Model get actually calculated based on a set of more tangible parameters, describing the experimental set-up, that serves as a basis of the Dynamic Model. These intermediate parameters are according to @fishman_temperature_1987: $\theta^{*}$: the temperature, leading to a maximal chilling effect, $\theta_c$ the highest temperature which still gives a positive response, $\tau$: the time needed to accumulate one critical portion of DBF under optimal temperature conditions and $\pi_c$ and the length of the cycle in a two-temperature regime, which leads to complete chilling negation. 
Other parameters describing the experiment, include the alternated temperatures of the experiment ($\theta_1=297K$, $\theta_2=279K$), and the fixed relation of these two temperatures ($\eta = \frac{1}{3}$). The $E_0$ to $A_1$ parameters get estimated on $\theta^{*}$, $\theta_c$, $\tau$ and $\pi_c$ So @egea_reducing_2021 proposed run a global optimization procedure on the intermediate parameters instead, because they are measured in Kelvin and hours, and boundaries of the search space are easier to set. Unfortunately, this involved to dig through some nasty looking equations, check out @egea_reducing_2021 and the original publication of the Dynamic Model, equations 33 to 38 [@fishman_temperature_1987]. In the end, a clean conversion is not possible for $A_1$ and $A_0$, they need to be estimated using an optimization problem.

Here is the set of equations that need to be solved (taken from @egea_reducing_2021):

$$
\begin{align*}
E_1=\frac{E_0-E_1}{e^{(E_1-E_0)*q}-1}*\frac{1}{ln(1-e^{(E_0-E1)*q})}\\
A_1=-e^{\frac{E_1}{\theta^{*}}}*\frac{ln(1-e^{(E_0-E_1)*q})}{\tau}\\
A_0=A_1e^{(\frac{E_0-E_1}{\theta_c})}\\
\frac{e^{(\frac{E_1-E_0}{\theta_c})}-e^{(\frac{E_1-E_0}{\theta_1})}}{e^{(\frac{E_1-E_0}{\theta_2})}-e^{(\frac{E_1-E_0}{\theta_1})}}=\frac{1-e^{-(k_1(\theta_2)*(1-\eta)*\pi_c)}}{1-e^{-([k_1(\theta_1)*\eta+k_1(\theta_2)*(1-\eta)]*\pi_c)}}\\
\text{with } q=\frac{1}{\theta^{*}}+\frac{1}{\theta_c}\text{; }\theta_1=297K\text{; }\theta_2=279K\text{; }\eta=\frac{1}{3}
\end{align*}
$$


To convert the intermediate model parameters, you can use the function `LarsChill::convert_parameters()`. It is written to take all 12 PhenoFlex model parameters, because at the time that was the easiest way for me to implement it. But it only affects the four intermediate model parameters

Here is an example

```{r convert_new_to_old, message=FALSE, warning=FALSE}
#       yc   zc   s1   Tu  theta_star theta_c tau  pie_cTf Tu Tb slope
par <- c(40, 190, 0.5, 25,  281,      287,     30, 24,  4, 36,  4,  1.60)
LarsChill::convert_parameters(par)

```

Luckily, this is also what @fishman_temperature_1987 calculated for these sets of intermediate parameters, so it seems that the function is working alright (if you want to compare, check first row of Table 1, @fishman_temperature_1987).

Because A0 and A1 get estimated using an optimization problem, it could theoretically happen that the optimization algorithm fails or that no solution is available. This can be problematic inside an optimization algorithm, so I included options how to handle such a failure to converge. Check details of the `failure_return` argument.

You need to adjust the evaluation functions if you want to use the intermediate model parameters in your optimization problem. Conveniently, PhenoFlex was coded in a modular way, so that evaluation functions can be modified. Inconveniently, PhenoFlex has a quite nested code structure, so that it is at first a bit challenging to find out what exactly needs to be adjusted. The argument `modelfn` of the `phenologyFitter()` function controls the function, that calculates bloom dates based on the supplied temperature data and parameters. If we want to exchange the $E_0$ to $A_1$ parameters with the intermediate ones, adjusting the input of the `modelfn` argument is the way to go. 

```{r gdh_wrapper, message=FALSE, warning=FALSE}

chillR::PhenoFlex_GDHwrapper

```

As you can see, the `PhenoFlex_GDHwrapper` wrapper is a relatively simple funciton. It takes `x` and `par` as inputs. `x` should be of the same format as tge output of the `chillR::genSeasonList()` function, it produces a list of data.frames, each data.frame has three columns: 'Temp', 'JDay' and 'Year'. `par` is a numeric vector with twelve entries, containing the PhenoFlex model parameters. Pay attention, that the order of parameters is correct, otherwise the function may not work or produce funny results. The first par of the code ensures that temperatures of the heat submodel make sense, the base temperature $T_b$ must be lower than optimal temperature $T_u$ and secondly, $T_u$ should not be larger than the critical temperature $T_c$. The next part of the code inserts the model parameters and the temperature data into PhenoFlex. PhenoFlex returns the bloomindex, this is not the bloom date but indicates at which row of the temperature data.frame `x` the accumulated heat exceeds the heat requirement $z_c$. The last part of the code calculates the bloom date, it has a routine what to do when the accumulated heat never exceeds $z_c$ (it returns an `NA` to the `phenologyFitter()` function) or it calculates the Julian Day (with digits). The bloom date calculation looks at first glance a bit complicated, but it accounts for the hour when the requirement is met. When it is met at noon at 12:00, it returns the Julian Day without alteration. If it is earlier, it subtracts a fraction and if it is later than noon it adds a fraction. 

Here is an example with intermediate model parameters:

```{r gdh_wrapper_modified, message=FALSE, warning=FALSE}

PhenoFlex_GDHwrapper_adjusted <- function (x, par) 
{
    if (par[4] <= par[11]) 
        return(NA)
    if (par[10] <= par[4]) 
        return(NA)
  
  #convert bloom dates
  par_converted <- LarsChill::convert_parameters(par)
    bloomindex <- PhenoFlex(temp = x$Temp, times = seq_along(x$Temp), 
        yc = par_converted[1], zc = par_converted[2], s1 = par_converted[3], Tu = par_converted[4], E0 = par_converted[5], 
        E1 = par_converted[6], A0 = par_converted[7], A1 = par_converted[8], Tf = par_converted[9], Tc = par_converted[10], 
        Tb = par_converted[11], slope = par_converted[12], Imodel = 0L, basic_output = TRUE)$bloomindex
    if (bloomindex == 0) 
        return(NA)
    JDay <- x$JDay[bloomindex]
    JDaylist <- which(x$JDay == JDay)
    n <- length(JDaylist)
    if (n == 1) 
        return(JDay)
    return(JDay + which(JDaylist == bloomindex)/n - 1/(n/ceiling(n/2)))
}
```

Downside of this approach is, that the conversion happens for each bloom date calculation seperately. But it would be necissary to convert it once and then calculate bloom dates for all the `SeasonList` entries. Unfortunately, the `modelfn` argument is the only way to customize the functions without having to build a whole custom version of `phenologyFitter()` function. I address this shortcoming in the chapter on customized model calibration. 

## Intermediate chill submodel parameters

Adjusting the GDH-wrapper function is also the easiest way to **fix** model parameters. Here is an example with $T_c$ fixed at 36°C. Now par should have only 11 entries, because we fixed Tc. Pay attention, that you incert the fixed parameters at the right position or correct the indices in the later code, so that the parameters are assigned correctly in the PhenoFlex function call. You can of course fix more model parameters, if you want to. Also, make sure that you remove the fixed parameter from `par.guess` and the search ranges when running the `phenologyFitter()` function.

```{r}
PhenoFlex_GDHwrapper_fixed <- function (x, par, Tc = 36) 
{
  par <- c(par[1:9], Tc, par[10:11])
    if (par[4] <= par[11]) 
        return(NA)
    if (par[10] <= par[4]) 
        return(NA)
    bloomindex <- PhenoFlex(temp = x$Temp, times = seq_along(x$Temp), 
        yc = par[1], zc = par[2], s1 = par[3], Tu = par[4], E0 = par[5], 
        E1 = par[6], A0 = par[7], A1 = par[8], Tf = par[9], Tc = par[10], 
        Tb = par[11], slope = par[12], Imodel = 0L, basic_output = TRUE)$bloomindex
    if (bloomindex == 0) 
        return(NA)
    JDay <- x$JDay[bloomindex]
    JDaylist <- which(x$JDay == JDay)
    n <- length(JDaylist)
    if (n == 1) 
        return(JDay)
    return(JDay + which(JDaylist == bloomindex)/n - 1/(n/ceiling(n/2)))
}

```


## Alternative optimization algorithm MEIGO with additional parameter constraints

As you can see, customizing the evaluation function is relatively simple. It gets a bit more complicated when you want to try out a different optimization algorithm than the simulated annealing function, implemented in the `phenologyFitter()` function. For example, I wanted to use the optimization framework `MEIGO` [@egea_meigo_2014]. `MEIGO` is also available on bioconductor, a platform where you can access R packages similar to CRAN. The installation via bioconductor is in my opinion less convenient than via CRAN and installing MEIGOR package was error-prone. As a quick fix, I mirrored the core of the MEIGOR package in my custom R package LarsChill (quite an original name, I know) <https://github.com/larscaspersen/addition_chillR>. Here you can find the original vignette for MEIGOR: <https://www.bioconductor.org/packages/release/bioc/manuals/MEIGOR/man/MEIGOR.pdf>. I only took the function for the Enhanced Scatter Search (ESS), which you can find via `LarsChill::custom_essr()`, but the functionality is just the same as in the original MEIGOR package. 

The ESS has some advantages and disadvantages compared to the simulated annealing algorithm. It was developed for complex optimization problems, it allows to screen for many different sets of model parameters, something I had the feeling the standard `phenologyFitter()` function was lacking. It is also relatively fast for small datasets (with <100 observations). You can specify additional inequality constraints when setting up the optimization problem. As you saw in the previous example, also the GDH_wrapper has some additional constraints implemented, but MEIGOR makes these easier to detect and to adjust and it also allows to specify acceptable ranges. I also like, that the function returns all the intermediate solutions that were surpassed by other sets of parameters in the course of the optimization run, it also returns the intermediate error scores, convenient if you want to make sure that the algorithm has converged or not. A big disadvantage is, that the speed of the ESS algorithm deteriorates quite fast for larger datasets, so if you have lots of observations in the calibration dataset it is better to stick with the simulated annealing algorithm used in the phenologyFitter function. 

To optimize PhenoFlex with another algorithm involves a little bit more work. The ESS optimization algorithm needs a function that calculates the model error for a particular set of parameters and temperature data. In most optimization problems model error is measured as Residual Sum of Squares (RSS), which is in our case simply the sum of the squared differences between predicted and observed bloom dates. The `PhenoFlex_GDH_wrapper()` function, however, only returns the bloom date for one season of temperatures and it does not even compare the prediction to the observed bloom dates. The function taking care of calculating the RSS is a hidden function called `chillR:::chifull()`. Note that I used three colons, when referring to the function, because this notation allows to access "hidden" functions, that did not get exported when creating the chillR package.  

I decided to maintain the modular structure of the `phenologyFitter()` function, where you specify the function how to calculate a bloom date with the `modelfn` argument, like with the `PhenoFlex_GDH_wrapper()` function. The evaluation function needs to do three things: 

- calculate bloom dates based on the temperature data specifeid in `SeasonList`
- calculate RSS by comparing the predicted bloom dates with the observed ones, specified in `bloomJDays`
- check model parameters for additional constraints

Here is an example of an evaluation function, that is compatible with the ESS algorithm of MEIGOR. I tried to 
bundle all the different cusotm evaluaiton functions and wrapper functions in a seperate package called
`evalpheno`, you can find the package here: <https://github.com/larscaspersen/eval_phenoflex>

```{r}
evalpheno::evaluation_function_meigo
```

As you can see, the evaluation functions is actually quite simple. At first we predict bloom dates, using the entries of `SeasonList`, t the function to calculate bloom dates specified in `modelfn` and the parameters specified in `x`(in the vignette for the MEIGOR package they always called the vector of the parameter `x`, while in PhenoFlex it is the name for the temperature data. Because I was not sure if the naming affected something, I followed the naming convention of the vignette, though it might be confusing.).

In case there is an NA in the predicted bloom dates, the value gets replaced with a value specified in `na_penalty`. Next, predicted and observed bloom dates get compared and the RSS is calculated and saved in the object `F`. The last and longest part is about the inequality constraints. The first three of the constrains should be familiar, as they are the same as in the PhemoFlex_GDH_wapper() function. Constrains 4 and 5 are new, relate to the $Q_{10}$ metric, that expresses by which factor a biological process speeds up for an increase in temperature by 10°C [@hegarty_temperature_1973]. In biological systems $Q_{10}$ values of 1.5 to 3.5 are deemed realisitic [@egea_reducing_2021]. In the early PhenoFlex papers [@luedeling_phenoflex_2021; @fernandez_unusually_2022] the $Q_{10}$ metric was checked *after* the calibration, but I think it makes even more sense to check the metric *during* the calibration. The results of the inequality constraints get saved in the vector `g`. Both, the error function `F` and the results of the inequality constrains `g` get returned to the optimization function. 

Before running the optimization function, we can specify acceptable upper and lower ranges for the inequality constrains, similar to how you do it for the search space of the model parameters. 

Here is an example of the specifications I made when calibrating PhenoFlex for a large dataset of temperate fruit trees [@caspersen_contrasting_2025]:

```{r, eval=FALSE}
#search space of model parameters
#        yc      zc     s1      Tu      theta_c   tau      piec    Tf     Tb     slope
x_0 <- c(24.79,	337.04,	0.2529,	17.72,	285.54,	   45.67,	  29.49,	2.97,	1.87,	2.69)
x_U <- c(80,    500,    1.0,    30,     287,       48,      50,    10,    10,     5.00)
x_L <- c(20,    100,    0.1,    15,     284,       16,      24,     2,     2,     1.2)

#limits for the inequality constraints
#         #gdh parameters   #q10 for E0 and E1
c_L <- c(  0,   0,   0,     1.5, 1.5)
c_U <- c(Inf, Inf, Inf,     3.5, 3.5)

problem<-list(f="evalpheno::eval_phenoflex_single_twofixed",
              x_0 = x_0,
              x_L = x_L,
              x_U = x_U,
              c_L = c_L, 
              c_U = c_U)


#options for fitter
opts<-list(#maxeval = 1000,
  maxtime = 60 * 10, 
  local_solver = 'DHC', 
  local_bestx = 1)

LarsChill::custom_essr(problem = problem,
                       opts = options,
                       modelfn = custom_PhenoFlex_GDHwrapper,
                       bloomJDays = pheno,
                       SeasonList = season_cal_list)
```

The first part is about the search space of the model parameters. I decided to optimize based on the intermediate model parameters and to fix two of the model parameters ($\theta^{*} = 279$, $T_c=36$). `x_0` is the initial guess, `x_L` the lower search range and `x_U` the upper range. The upper acceptable limit of the inequality constrain is specified in `c_U` and the lower limit in `c_L`. In the first three constrains for the heat submodel temperature parameters, we excluded any negative value, in the last two relating to the $Q_{10}$ metric, we excluded values outside the range of 1.5 to 3.5. All of that information is bundled in a list called `problem`. There it is also specified which **evaluation function** we are using, here I use the function `evalpheno::eval_phenoflex_single_twofixed`. Make sure that you omit the paranthesis after function name, because you want to only specify the name and not exexcute the function. The problem-list gets followed by the option list, here you specify settings of the optimization algorithm. `maxtime` specifies the time-limit for how long the algortihm should optimize (in seconds). `local_solver` specifies which optimization algorithm should be run when ESS found a set of model parameter leading to a lower RSS. The local solver makes a more refined narrower search around the newly found, better model parameters. `local_bestx` specifies how often the local search is called. When set to 1, local search is only triggered immediately after a better set is found, higher values would postpone the local search for some further iterations, that can be beneficial when the global search quickly finds even better parameter sets. You can also specifiy how many iterations the algorithms should make with `maxeval`. For more options, check the MEIGOR vignette. 

Lastly, the problem and option list get supplied to the `LarsChill::custom_essr()` funciton. This function does the optimization and should hopefully return good model parameters for your dataset. As you may have noticed, I also supplied three further arguments to the function: `modelfn`, `bloomJDays` and `SeasonList`. These are inputs for the evaluation function specified in the problem list. They are the same when running the `phenologyFitter()` function.


## Shared chill and heat accumulation submodels but cultivar-specific requirement parameters: The combined fitting approach
