---
title: "Intermediate Model Parameters"
output: distill::distill_article
bibliography: vignette_phenoflex.bib
csl: elsevier-harvard-modifed.csl
---

## Motivation

PhenoFlex is a phenology model developed by @luedeling_phenoflex_2021, accessible via the chillR package [@luedeling_chillr_2023]. During my PhD, I primarily worked with PhenoFlex, developing customized functions to improve its usability. These functions helped streamline tasks such as integrating various calibration methods, algorithms, and fitting multiple phenological stages simultaneously.

The standard PhenoFlex routines, including model runs, calibration, cross-validation, and plotting outputs for the chill and heat accumulation submodels, are well-documented by @urbach_phenoflex_2021. For further details, see the the [PhenoFlex vignette](https://cran.r-project.org/web/packages/chillR/vignettes/PhenoFlex.html). These routines formed the foundation for early phenology studies using PhenoFlex [@luedeling_phenoflex_2021; @fernandez_unusually_2022].

In these studies, numerous calibration iterations were required. The process involved running the calibration fitting function `chillR::PhenologyFitter()`, waiting for the model to estimate parameters, and evaluating the prediction accuracy. If the results were satisfactory, calibration would proceed using the updated parameters as a new starting point. In cases where predictions didnâ€™t improve, the search space would be adjusted (either narrowed or expanded) to help the optimization algorithm find better parameter sets. Typically, between 15 and 30 rounds of iteration were needed to finalize the parameter set. While this approach resulted in reasonably accurate parameters (with an RMSE below 4 days), the process was time-consuming and labor-intensive. Most notably, it was not easily scalable due to the manual steps involved, such as checking temperature response plots and adjusting search ranges.

One of my first tasks as a PhD student was to apply PhenoFlex to an extensive phenology dataset assembled as part of the Adapting Mediterranean Orchards (AdaMedOr) project [@luedeling_long-term_2024]. The dataset included 270 cultivars from seven temperate fruit tree species (almond, pistachio, apple, pear, plum, sweet cherry, apricot). More than 100 cultivars had 20 or more observations [@caspersen_contrasting_2025], which is considered the minimum required for model calibration [@urbach_phenoflex_2021]. For most cultivars, we had exactly 20 observations, meaning that after a 75%-calibration / 25%-validation split, only five observations remained in the validation set. Validating the model on such a small dataset seemed problematic, so we decided to implement cross-validation, which added more complexity to the calibration process.

## Theoretical Background

Together with Jose Egea, member of the AdaMedOr project consortium and experienced in global optimization problems, we hypothesized that part of the calibration problem are the ranges of the model parameters. In particular the parameters controlling the chill submodel. The Dynamic Model [@fishman_temperature-dependence_1987; @fishman_temperature_1987] consists of two ordinary differential equation (ODE) modeling the build-up and degradation of some (hypothetical) precursor of a dormancy breaking factor (PDBF). After a critical amount of PDBF is accumulated, a certain share gets converted to a non-degradable dormancy breaking factor (DBF). For the ODEs controlling build-up and degradation of PDBF four parameters are needed: $E_0$: activation energy for forming PDBF, $A_0$: amplitude of the formation process, $E_1$: activation energy for degrading PDBF and $A_1$: amplitude of the degradation process. All of these parameters are not really tangible for most people, so setting boundaries is difficult. It is even more difficult, because the default value of $A_1$ for example is on a ridiculous scale, 5.939917e13, that is a number wit 13 zeros before the digit! Good luck finding an appropriate search space that does not limit the algorithm too much but still is manageable. By the way, the default search space in @urbach_phenoflex_2021 might be too narrow, as in the original paper describing the Dynamic Model parameter they ranged from 0.1797e15 to 0.1875e17, while there the search space is "only" between 5.e13 to 6.e13. Also, they had initially ridiculous ranges in the other estimated model parameters, for instance $A_0$ ranged from 0.1386e4 to 0.1405e15. So in summary, finding appropriate ranges for these parameters is a difficult task, and even if you find them, it is a difficult search space for the optimization algorithm to navigate. Based on my limited experience, the optimizer is often "stuck" for these parameters and does not offer different sets of parameters for $E_0$, $E_1$, $A_0$ and $A_1$.

@egea_reducing_2021 point out, that the $E_0$ to $A_1$ parameters of the Dynamic Model get actually calculated based on a set of more tangible parameters, describing the experimental set-up, that serves as a basis of the Dynamic Model. These intermediate parameters are according to @fishman_temperature_1987: $\theta^{*}$: the temperature, leading to a maximal chilling effect, $\theta_c$ the highest temperature which still gives a positive response, $\tau$: the time needed to accumulate one critical portion of DBF under optimal temperature conditions and $\pi_c$ and the length of the cycle in a two-temperature regime, which leads to complete chilling negation. 
Other parameters describing the experiment, include the alternated temperatures of the experiment ($\theta_1=297K$, $\theta_2=279K$), and the fixed relation of these two temperatures ($\eta = \frac{1}{3}$). The $E_0$ to $A_1$ parameters get estimated on $\theta^{*}$, $\theta_c$, $\tau$ and $\pi_c$ So @egea_reducing_2021 proposed run a global optimization procedure on the intermediate parameters instead, because they are measured in Kelvin and hours, and boundaries of the search space are easier to set. Unfortunately, this involved to dig through some nasty looking equations, check out @egea_reducing_2021 and the original publication of the Dynamic Model, equations 33 to 38 [@fishman_temperature_1987]. In the end, a clean conversion is not possible for $A_1$ and $A_0$, they need to be estimated using an optimization problem.

Here is the set of equations that need to be solved (taken from @egea_reducing_2021):

$$
\begin{align*}
E_1=\frac{E_0-E_1}{e^{(E_1-E_0)*q}-1}*\frac{1}{ln(1-e^{(E_0-E1)*q})}\\
A_1=-e^{\frac{E_1}{\theta^{*}}}*\frac{ln(1-e^{(E_0-E_1)*q})}{\tau}\\
A_0=A_1e^{(\frac{E_0-E_1}{\theta_c})}\\
\frac{e^{(\frac{E_1-E_0}{\theta_c})}-e^{(\frac{E_1-E_0}{\theta_1})}}{e^{(\frac{E_1-E_0}{\theta_2})}-e^{(\frac{E_1-E_0}{\theta_1})}}=\frac{1-e^{-(k_1(\theta_2)*(1-\eta)*\pi_c)}}{1-e^{-([k_1(\theta_1)*\eta+k_1(\theta_2)*(1-\eta)]*\pi_c)}}\\
\text{with } q=\frac{1}{\theta^{*}}+\frac{1}{\theta_c}\text{; }\theta_1=297K\text{; }\theta_2=279K\text{; }\eta=\frac{1}{3}
\end{align*}
$$

## Converting Parameters

To convert the intermediate model parameters, you can use the function `LarsChill::convert_parameters()`. It is written to take all 12 PhenoFlex model parameters, because at the time that was the easiest way for me to implement it. But it only affects the four intermediate model parameters

Here is an example

```{r convert_new_to_old, message=FALSE, warning=FALSE}
#       yc   zc   s1   Tu  theta_star theta_c tau  pie_cTf Tu Tb slope
par <- c(40, 190, 0.5, 25,  281,      287,     30, 24,  4, 36,  4,  1.60)
LarsChill::convert_parameters(par)

```

Luckily, this is also what @fishman_temperature_1987 calculated for these sets of intermediate parameters, so it seems that the function is working alright (if you want to compare, check first row of Table 1, @fishman_temperature_1987).

Because A0 and A1 get estimated using an optimization problem, it could theoretically happen that the optimization algorithm fails or that no solution is available. This can be problematic inside an optimization algorithm, so I included options how to handle such a failure to converge. Check details of the `failure_return` argument.


## Adjusting the Wrapper Function for intermediate parameters

You need to adjust the evaluation functions if you want to use the intermediate model parameters in your optimization problem. Conveniently, PhenoFlex was coded in a modular way, so that evaluation functions can be modified. Inconveniently, PhenoFlex has a quite nested code structure, so that it is at first a bit challenging to find out what exactly needs to be adjusted. The argument `modelfn` of the `phenologyFitter()` function controls the function, that calculates bloom dates based on the supplied temperature data and parameters. If we want to exchange the $E_0$ to $A_1$ parameters with the intermediate ones, adjusting the input of the `modelfn` argument is the way to go. 

```{r gdh_wrapper, message=FALSE, warning=FALSE}

chillR::PhenoFlex_GDHwrapper

```
As you can see, the `PhenoFlex_GDHwrapper` wrapper is a relatively simple funciton. It takes `x` and `par` as inputs. `x` should be of the same format as tge output of the `chillR::genSeasonList()` function, it produces a list of data.frames, each data.frame has three columns: 'Temp', 'JDay' and 'Year'. `par` is a numeric vector with twelve entries, containing the PhenoFlex model parameters. Pay attention, that the order of parameters is correct, otherwise the function may not work or produce funny results. The first par of the code ensures that temperatures of the heat submodel make sense, the base temperature $T_b$ must be lower than optimal temperature $T_u$ and secondly, $T_u$ should not be larger than the critical temperature $T_c$. The next part of the code inserts the model parameters and the temperature data into PhenoFlex. PhenoFlex returns the bloomindex, this is not the bloom date but indicates at which row of the temperature data.frame `x` the accumulated heat exceeds the heat requirement $z_c$. The last part of the code calculates the bloom date, it has a routine what to do when the accumulated heat never exceeds $z_c$ (it returns an `NA` to the `phenologyFitter()` function) or it calculates the Julian Day (with digits). The bloom date calculation looks at first glance a bit complicated, but it accounts for the hour when the requirement is met. When it is met at noon at 12:00, it returns the Julian Day without alteration. If it is earlier, it subtracts a fraction and if it is later than noon it adds a fraction. 

Here is an example with intermediate model parameters:


```{r gdh_wrapper_modified, message=FALSE, warning=FALSE}

PhenoFlex_GDHwrapper_adjusted <- function (x, par) 
{
    if (par[4] <= par[11]) 
        return(NA)
    if (par[10] <= par[4]) 
        return(NA)
  
  #convert bloom dates
  par_converted <- LarsChill::convert_parameters(par)
    bloomindex <- PhenoFlex(temp = x$Temp, times = seq_along(x$Temp), 
        yc = par_converted[1], zc = par_converted[2], s1 = par_converted[3], Tu = par_converted[4], E0 = par_converted[5], 
        E1 = par_converted[6], A0 = par_converted[7], A1 = par_converted[8], Tf = par_converted[9], Tc = par_converted[10], 
        Tb = par_converted[11], slope = par_converted[12], Imodel = 0L, basic_output = TRUE)$bloomindex
    if (bloomindex == 0) 
        return(NA)
    JDay <- x$JDay[bloomindex]
    JDaylist <- which(x$JDay == JDay)
    n <- length(JDaylist)
    if (n == 1) 
        return(JDay)
    return(JDay + which(JDaylist == bloomindex)/n - 1/(n/ceiling(n/2)))
}
```
Downside of this approach is, that the conversion happens for each bloom date calculation seperately. But it would be necissary to convert it once and then calculate bloom dates for all the `SeasonList` entries. Unfortunately, the `modelfn` argument is the only way to customize the functions without having to build a whole custom version of `phenologyFitter()` function. I address this shortcoming in the chapter on customized model calibration. 